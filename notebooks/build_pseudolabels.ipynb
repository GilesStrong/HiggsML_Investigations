{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import optparse\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirLoc = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = h5py.File(dirLoc + 'train.hdf5', \"r+\")\n",
    "testingData = h5py.File(dirLoc + 'testing.hdf5', \"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_trainingData = h5py.File(dirLoc + 'pseudo_train.hdf5', \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0\n",
      "Training data contains 20001 events\n",
      "Adding 2000 test events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudo data now contains 22001 events\n",
      "fold_1\n",
      "Training data contains 20001 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22001 events\n",
      "fold_2\n",
      "Training data contains 20001 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22001 events\n",
      "fold_3\n",
      "Training data contains 20000 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22000 events\n",
      "fold_4\n",
      "Training data contains 20000 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22000 events\n",
      "fold_5\n",
      "Training data contains 20000 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22000 events\n",
      "fold_6\n",
      "Training data contains 20000 events\n",
      "Adding 2000 test events\n",
      "Pseudo data now contains 22000 events\n",
      "fold_7\n",
      "Training data contains 19999 events\n",
      "Adding 1999 test events\n",
      "Pseudo data now contains 21998 events\n",
      "fold_8\n",
      "Training data contains 19999 events\n",
      "Adding 1999 test events\n",
      "Pseudo data now contains 21998 events\n",
      "fold_9\n",
      "Training data contains 19999 events\n",
      "Adding 1999 test events\n",
      "Pseudo data now contains 21998 events\n"
     ]
    }
   ],
   "source": [
    "for fold in trainingData:\n",
    "    print(fold)\n",
    "    #Load original training data\n",
    "    inputs = np.array(trainingData[fold + '/inputs'])\n",
    "    train = pandas.DataFrame(inputs, columns=[f'in_{i}' for i in range(len(inputs[0]))])\n",
    "    train['gen_weight_original'] = np.array(trainingData[fold + '/orig_weights'])\n",
    "    train['gen_weight'] = train['gen_weight_original']\n",
    "    train['gen_target'] = np.array(trainingData[fold + '/targets'])\n",
    "    print('Training data contains', len(train), 'events')\n",
    "    \n",
    "    #Get well classified testing data\n",
    "    inputs = np.array(testingData[fold + '/inputs'])\n",
    "    test = pandas.DataFrame(inputs, columns=[f'in_{i}' for i in range(len(inputs[0]))])\n",
    "    test['preds'] = np.array(testingData[fold + '/pred'])\n",
    "    test['conf'] = np.abs(test.loc[:, 'preds']-0.5)\n",
    "    test.sort_values(by=['conf'], inplace=True, ascending=False)\n",
    "    \n",
    "    #Build pseudo data\n",
    "    n_label = min(int(FRAC*len(train)), len(test))\n",
    "    test = test[:n_label]\n",
    "    test['gen_target'] = np.round(test['preds'].astype('float32'))\n",
    "    test['gen_weight_original'] = 0\n",
    "    test.loc[test.gen_target==1, 'gen_weight_original'] = np.mean(train.loc[train.gen_target==1, 'gen_weight_original'])\n",
    "    test.loc[test.gen_target==0, 'gen_weight_original'] = np.mean(train.loc[train.gen_target==0, 'gen_weight_original'])\n",
    "    test['gen_weight'] = test['gen_weight_original']\n",
    "    print('Adding', len(test), 'test events')\n",
    "\n",
    "    #Combine & save\n",
    "    pseudo = train.append(test[['gen_weight_original', 'gen_target', 'gen_weight']+[x for x in test.columns if 'in_' in x]], ignore_index=True)\n",
    "    pseudo.sample(frac=1)\n",
    "    print('Pseudo data now contains', len(pseudo), 'events')\n",
    "    \n",
    "    grp = pseudo_trainingData.create_group(fold)\n",
    "    \n",
    "    X = pseudo[[x for x in pseudo.columns if 'in_' in x]].values.astype('float32')\n",
    "    inputs = grp.create_dataset(\"inputs\", shape=X.shape, dtype='float32')\n",
    "    inputs[...] = X\n",
    "    \n",
    "    pseudo.loc[pseudo.gen_target == 0, 'gen_weight'] = pseudo.loc[pseudo.gen_target == 0, 'gen_weight']/np.sum(pseudo.loc[pseudo.gen_target == 0, 'gen_weight'])\n",
    "    pseudo.loc[pseudo.gen_target == 1, 'gen_weight'] = pseudo.loc[pseudo.gen_target == 1, 'gen_weight']/np.sum(pseudo.loc[pseudo.gen_target == 1, 'gen_weight'])\n",
    "\n",
    "    y = pseudo['gen_target'].values.astype('int')\n",
    "    targets = grp.create_dataset(\"targets\", shape=y.shape, dtype='int')\n",
    "    targets[...] = y\n",
    "\n",
    "    X_weights = pseudo['gen_weight'].values.astype('float32')\n",
    "    weights = grp.create_dataset(\"weights\", shape=X_weights.shape, dtype='float32')\n",
    "    weights[...] = X_weights\n",
    "\n",
    "    X_orig_weights = pseudo['gen_weight_original'].values.astype('float32')\n",
    "    orig_weights = grp.create_dataset(\"orig_weights\", shape=X_weights.shape, dtype='float32')\n",
    "    orig_weights[...] = X_orig_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
